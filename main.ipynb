{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Unattended Baggage Claim"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from imutils.video import FPS\n",
    "from IPython.display import Video\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display function for Jupyter Notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def plt_imshow(title, image):\n",
    "\t# convert the image frame BGR to RGB color space and display it\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\tplt.imshow(image)\n",
    "\tplt.title(title)\n",
    "\tplt.grid(False)\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Argument parser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# since we are using Jupyter Notebooks we can replace our argument\n",
    "# parsing code with *hard coded* arguments and values\n",
    "args = {\n",
    "\t\"input\" : \"video/unattended-bag.mp4\",\n",
    "\t\"output\" : \"output.avi\",\n",
    "\t\"prototxt\": \"MobileNetSSD_deploy.prototxt.txt\",\n",
    "\t\"model\": \"MobileNetSSD_deploy.caffemodel\",\n",
    "\t\"confidence\" : 0.2\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect\n",
    "CLASSES = [\"background\",\n",
    "\t\t   \"aeroplane\",\n",
    "\t\t   \"bicycle\",\n",
    "\t\t   \"bird\",\n",
    "\t\t   \"boat\",\n",
    "\t\t   \"bottle\",\n",
    "\t\t   \"bus\",\n",
    "\t\t   \"car\",\n",
    "\t\t   \"cat\",\n",
    "\t\t   \"chair\",\n",
    "\t\t   \"cow\",\n",
    "\t\t   \"diningtable\",\n",
    "\t\t   \"dog\",\n",
    "\t\t   \"horse\",\n",
    "\t\t   \"motorbike\",\n",
    "\t\t   \"person\",\n",
    "\t\t   \"pottedplant\",\n",
    "\t\t   \"sheep\",\n",
    "\t\t   \"sofa\",\n",
    "\t\t   \"train\",\n",
    "\t\t   \"tvmonitor\"]\n",
    "# generate a set of bounding box colors\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "# debug message\n",
    "print(\"[INFO] loading model...\")\n",
    "# load our serialized model from disk\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] opening video file...\n"
     ]
    }
   ],
   "source": [
    "# debug message\n",
    "print(\"[INFO] opening video file...\")\n",
    "# grab a reference to the video file\n",
    "# initialize pointer to output video file\n",
    "vs = cv2.VideoCapture(args[\"input\"])\n",
    "writer = None\n",
    "# and initialize the FPS counter\n",
    "fps = FPS().start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] elapsed time: 11.68\n",
      "[INFO] approx. FPS: 34.17\n"
     ]
    }
   ],
   "source": [
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "\t# grab the next frame\n",
    "\tframe = vs.read()[1]\n",
    "\n",
    "\t# if we did not grab a frame then we have reached the end of the\n",
    "\t# video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# resize the frame to have a maximum width of 300 pixels\n",
    "\tframe = imutils.resize(frame, width=400)\n",
    "\n",
    "\t# grab the frame dimensions and convert it to a blob\n",
    "\t(h, w) = frame.shape[:2]\n",
    "\t# calculate a 300x300 pixel blob from our image\n",
    "\tblob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
    "\n",
    "\t# pass the blob through the network and obtain the detections and\n",
    "\t# predictions\n",
    "\tnet.setInput(blob)\n",
    "\tdetections = net.forward()\n",
    "\n",
    " \t# loop over the detections\n",
    "\tfor i in np.arange(0, detections.shape[2]):\n",
    "\t\t# first we extract the confidence of the detection\n",
    "\t\t# there may be multiple detections\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# if the confidence is above our threshold (ex. 20%),\n",
    "\t\tif confidence > args[\"confidence\"]:\n",
    "\t\t\t# extract the index of the class label from the detection\n",
    "\t\t\tidx = int(detections[0, 0, i, 1])\n",
    "\t\t\t# then compute the (x, y)-coordinates of\n",
    "\t\t\t# the bounding box for the object\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t# extract the XY to draw the rectangle and display the label\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t# build a text label containing the class name and confidence\n",
    "\t\t\tlabel = \"{}: {:.2f}%\".format(CLASSES[idx],\n",
    "\t\t\t\tconfidence * 100)\n",
    "\t\t\t# draw a colored rectangle around the object using the extracted XY\n",
    "\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "\t\t\t\tCOLORS[idx], 2)\n",
    "\t\t\t# we want the label to display above the rectangle if there's room\n",
    "\t\t\t# else, just below the top\n",
    "\t\t\ty = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "\t\t\t# overlay the colored text on the image\n",
    "\t\t\tcv2.putText(frame, label, (startX, y),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "\n",
    "\t# update the FPS counter\n",
    "\tfps.update()\n",
    "\n",
    "\t# if the video writer is None *AND* we are supposed to write\n",
    "\t# the output video to disk initialize the writer\n",
    "\tif writer is None and args[\"output\"] is not None:\n",
    "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 20,\n",
    "\t\t\t(frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "\t# if the writer is not None, write the frame with recognized\n",
    "\t# faces to disk\n",
    "\tif writer is not None:\n",
    "\t\twriter.write(frame)\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# do a bit of cleanup\n",
    "vs.release()\n",
    "\n",
    "# check to see if the video writer point needs to be released\n",
    "if writer is not None:\n",
    "\twriter.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3.1 Copyright (c) 2000-2020 the FFmpeg developers\r\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.27)\r\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.3.1_4 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-libsoxr --enable-videotoolbox --disable-libjack --disable-indev=jack\r\n",
      "  libavutil      56. 51.100 / 56. 51.100\r\n",
      "  libavcodec     58. 91.100 / 58. 91.100\r\n",
      "  libavformat    58. 45.100 / 58. 45.100\r\n",
      "  libavdevice    58. 10.100 / 58. 10.100\r\n",
      "  libavfilter     7. 85.100 /  7. 85.100\r\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\r\n",
      "  libswscale      5.  7.100 /  5.  7.100\r\n",
      "  libswresample   3.  7.100 /  3.  7.100\r\n",
      "  libpostproc    55.  7.100 / 55.  7.100\r\n",
      "Input #0, avi, from 'output.avi':\r\n",
      "  Metadata:\r\n",
      "    encoder         : Lavf58.76.100\r\n",
      "  Duration: 00:00:19.95, start: 0.000000, bitrate: 2106 kb/s\r\n",
      "    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 400x224, 2106 kb/s, 20 fps, 20 tbr, 20 tbn, 20 tbc\r\n",
      "Stream mapping:\r\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\r\n",
      "Press [q] to stop, [?] for help\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mprofile High, level 1.3, 4:2:0, 8-bit\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0m264 - core 161 r3027 4121277 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=7 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=20 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\r\n",
      "Output #0, mp4, to 'unattended-bag-output.mp4':\r\n",
      "  Metadata:\r\n",
      "    encoder         : Lavf58.45.100\r\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 400x224, q=-1--1, 20 fps, 10240 tbn, 20 tbc\r\n",
      "    Metadata:\r\n",
      "      encoder         : Lavc58.91.100 libx264\r\n",
      "    Side data:\r\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\r\n",
      "frame=  399 fps=0.0 q=-1.0 Lsize=     605kB time=00:00:19.80 bitrate= 250.3kbits/s speed=32.1x    \r\n",
      "video:600kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.909178%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mframe I:2     Avg QP:20.20  size: 10065\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mframe P:113   Avg QP:22.57  size:  3310\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mframe B:284   Avg QP:27.81  size:   771\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mconsecutive B-frames:  1.8%  8.5%  4.5% 85.2%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mmb I  I16..4:  8.4% 82.4%  9.1%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mmb P  I16..4:  3.0% 12.9%  4.0%  P16..4: 29.7% 14.1% 12.6%  0.0%  0.0%    skip:23.7%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mmb B  I16..4:  0.6%  1.1%  0.5%  B16..8: 25.0%  6.5%  2.1%  direct: 1.7%  skip:62.4%  L0:44.4% L1:44.7% BI:10.9%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0m8x8 transform intra:62.6% inter:73.6%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mcoded y,uvDC,uvAC intra: 67.5% 57.6% 21.6% inter: 13.4% 12.9% 3.4%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mi16 v,h,dc,p: 59% 14%  3% 24%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 12% 26%  2%  4%  5%  5%  5%  2%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 44% 16% 13%  3%  5%  6%  5%  5%  3%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mi8c dc,h,v,p: 38% 21% 38%  3%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mWeighted P-Frames: Y:16.8% UV:8.0%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mref P L0: 56.8% 13.3% 18.9% 10.3%  0.8%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mref B L0: 80.8% 14.6%  4.6%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mref B L1: 93.5%  6.5%\r\n",
      "\u001B[1;36m[libx264 @ 0x7f858a00fa00] \u001B[0mkb/s:245.92\r\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i output.avi unattended-bag-output.mp4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<video width=\"320\" height=\"240\" controls>\n  <source src=\"output.mp4\" type=\"video/mp4\">\n</video>\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"output.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}